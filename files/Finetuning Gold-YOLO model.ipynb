{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP4otujrW1CR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIBNvJ1wGxPb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTsb5NzLW-02",
        "outputId": "eae27809-d015-4e65-d892-6ea9d2bb0f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBDMNyKMXId1",
        "outputId": "85ec3797-9af4-4a4d-931a-7cd36966a37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Research Project/Gold-YOLO\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/My Drive/Research Project/Gold-YOLO/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdbcvoYYHSe7",
        "outputId": "9c4cf361-bb98-4200-8b34-7f7cf8295c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " assets      old-runs\n",
            " configs     README.md\n",
            " data\t     requirements.txt\n",
            " deploy      Research_project_YOLO_comparisions.ipynb\n",
            " docs\t     runs\n",
            " gold_yolo  'THIRD PARTY OPEN SOURCE SOFTWARE NOTICE.txt'\n",
            " LDPolyp     tools\n",
            " LICENSE     yolov6\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1Oj87zxhNmv",
        "outputId": "9f9101c6-180c-4502-867c-4a2551c6016c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.18.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.10.0.84)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.66.5)\n",
            "Collecting addict>=2.4.0 (from -r requirements.txt (line 11))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.17.0)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.0.8)\n",
            "Collecting onnx>=1.10.0 (from -r requirements.txt (line 14))\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnx-simplifier>=0.3.6 (from -r requirements.txt (line 15))\n",
            "  Downloading onnx_simplifier-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting thop (from -r requirements.txt (line 16))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting mmcv==1.5.0 (from -r requirements.txt (line 17))\n",
            "  Downloading mmcv-1.5.0.tar.gz (530 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.7/530.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv==1.5.0->-r requirements.txt (line 17)) (24.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==1.5.0->-r requirements.txt (line 17)) (9.4.0)\n",
            "Collecting yapf (from mmcv==1.5.0->-r requirements.txt (line 17))\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.0.3)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (13.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.5.0->-r requirements.txt (line 17)) (8.2.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.5.0->-r requirements.txt (line 17)) (4.2.2)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.5.0->-r requirements.txt (line 17)) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv==1.5.0->-r requirements.txt (line 17)) (3.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (0.1.2)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_simplifier-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: mmcv\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv: filename=mmcv-1.5.0-py2.py3-none-any.whl size=807160 sha256=fffcc36ddf93ef5ee587e55e73ff2a7964a090816c87a6d8ed13cf130d708996\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/b4/5d/1250f6319cd64acea208a8cd5a3e600506381c05bd65343d22\n",
            "Successfully built mmcv\n",
            "Installing collected packages: addict, onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, yapf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, onnx-simplifier, nvidia-cusolver-cu12, mmcv, thop\n",
            "Successfully installed addict-2.4.0 mmcv-1.5.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 onnx-1.16.2 onnx-simplifier-0.4.36 thop-0.1.1.post2209072238 yapf-0.40.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "gPjdqQl7FurA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F-Ubi7XXku4",
        "outputId": "1aad6cda-3f8a-4a65-8f7d-a8a8e4335341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-14 04:31:47.099932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-14 04:31:47.120160: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-14 04:31:47.126240: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-14 04:31:47.140740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-14 04:31:48.272400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using 1 GPU for training... \n",
            "training args are: Namespace(data_path='/content/drive/MyDrive/Research Project/Gold-YOLO/data/dataset.yaml', conf_file='configs/gold_yolo-n.py', use_syncbn=False, img_size=640, batch_size=64, epochs=200, workers=8, device='0', eval_interval=20, eval_final_only=False, heavy_eval_range=50, check_images=False, check_labels=False, output_dir='./runs/train', name='exp', dist_url='env://', gpu_count=0, local_rank=-1, resume=False, write_trainbatch_tb=False, stop_aug_last_n_epoch=15, save_ckpt_on_last_n_epoch=-1, distill=False, distill_feat=False, quant=False, calib=False, teacher_model_path=None, temperature=20, fuse_ab=True, bs_per_gpu=32, rank=-1, world_size=1, save_dir='runs/train/exp')\n",
            "\n",
            "Train: Checking formats of images with 8 process(es): \n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "0 image(s) corrupted: 100% 11382/11382 [07:41<00:00, 24.69it/s] \n",
            "Train: Checking formats of labels with 8 process(es): \n",
            "11382 label(s) found, 0 label(s) missing, 2028 label(s) empty, 0 invalid label files: 100% 11382/11382 [16:48<00:00, 11.28it/s]\n",
            "Train: Final numbers of valid images: 11382/ labels: 11382. \n",
            "1544.7s for dataset initialization.\n",
            "Val: Checking formats of images with 8 process(es): \n",
            "0 image(s) corrupted: 100% 2862/2862 [01:21<00:00, 35.05it/s] \n",
            "Val: Checking formats of labels with 8 process(es): \n",
            "2862 label(s) found, 0 label(s) missing, 300 label(s) empty, 0 invalid label files: 100% 2862/2862 [04:36<00:00, 10.35it/s]\n",
            "Convert to COCO format\n",
            "100% 2862/2862 [00:00<00:00, 195847.78it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Research Project/Gold-YOLO/LDPolyp/annotations/instances_valid.json\n",
            "Val: Final numbers of valid images: 2862/ labels: 2862. \n",
            "359.3s for dataset initialization.\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): Sequential(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): Sequential(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimCSPSPPF(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv4): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "        (cv5): SimConv(\n",
            "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv6): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv7): SimConv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepGDNeck(\n",
            "    (low_FAM): SimFusion_4in()\n",
            "    (low_IFM): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): Conv(\n",
            "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer_c5): SimConv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (LAF_p4): SimFusion_3in(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv_fuse): SimConv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Inject_p4): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer_p4): SimConv(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (LAF_p3): SimFusion_3in(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv_fuse): SimConv(\n",
            "        (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Inject_p3): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (high_FAM): PyramidPoolAgg()\n",
            "    (high_IFM): TopBasicLayer(\n",
            "      (transformer_blocks): ModuleList(\n",
            "        (0): top_Block(\n",
            "          (attn): Attention(\n",
            "            (to_q): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_k): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_v): Conv2d_BN(\n",
            "              (c): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (0): ReLU6(inplace=True)\n",
            "              (1): Conv2d_BN(\n",
            "                (c): Conv2d(64, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path): Identity()\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)\n",
            "            (act): ReLU6(inplace=True)\n",
            "            (fc2): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (drop): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): top_Block(\n",
            "          (attn): Attention(\n",
            "            (to_q): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_k): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_v): Conv2d_BN(\n",
            "              (c): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (0): ReLU6(inplace=True)\n",
            "              (1): Conv2d_BN(\n",
            "                (c): Conv2d(64, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)\n",
            "            (act): ReLU6(inplace=True)\n",
            "            (fc2): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (drop): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (conv_1x1_n): Conv2d(352, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (LAF_n4): AdvPoolFusion()\n",
            "    (Inject_n4): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (LAF_n5): AdvPoolFusion()\n",
            "    (Inject_n5): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n5): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_preds_af): ModuleList(\n",
            "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds_af): ModuleList(\n",
            "      (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (cls_preds_ab): ModuleList(\n",
            "      (0): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds_ab): ModuleList(\n",
            "      (0): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Training start...\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]                                                             /usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "     0/199     2.535         0     2.328: 100%|██████████| 178/178 [02:51<00:00,  1.04it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:42<00:00,  1.84s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.25s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.47s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.149\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 0 | mAP@0.5: 0.02726998879449017 | mAP@0.50:0.95: 0.004962792991087102\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     1/199     2.013         0     2.158: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     2/199      1.61         0     2.192: 100%|██████████| 178/178 [02:49<00:00,  1.05it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     3/199     1.432         0     2.282: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     4/199     1.329         0     2.349: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     5/199     1.263         0      2.37: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     6/199     1.204         0      2.36: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     7/199     1.169         0     2.325: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     8/199      1.14         0     2.278: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "     9/199     1.115         0     2.225: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    10/199     1.087         0     2.171: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    11/199     1.069         0     2.117: 100%|██████████| 178/178 [02:47<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    12/199     1.048         0     2.077: 100%|██████████| 178/178 [02:49<00:00,  1.05it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    13/199     1.031         0     2.022: 100%|██████████| 178/178 [02:49<00:00,  1.05it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    14/199     1.017         0     1.988: 100%|██████████| 178/178 [02:47<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    15/199     1.005         0     1.952: 100%|██████████| 178/178 [02:48<00:00,  1.06it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    16/199    0.9985         0     1.925: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    17/199    0.9861         0     1.902: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    18/199     0.971         0     1.859: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    19/199    0.9699         0     1.845: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    20/199    0.9522         0     1.819: 100%|██████████| 178/178 [02:51<00:00,  1.04it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:56<00:00,  2.46s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=3.53s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=11.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.61s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 20 | mAP@0.5: 0.0374844479022477 | mAP@0.50:0.95: 0.0077820412400415855\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    21/199    0.9411         0     1.808: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    22/199    0.9376         0     1.785: 100%|██████████| 178/178 [02:48<00:00,  1.06it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    23/199    0.9312         0     1.781: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    24/199    0.9208         0     1.754: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    25/199    0.9182         0     1.741: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    26/199    0.9106         0     1.734: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    27/199     0.901         0     1.717: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    28/199       0.9         0     1.712: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    29/199    0.8915         0     1.695: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    30/199    0.8843         0      1.68: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    31/199    0.8817         0      1.68: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    32/199    0.8732         0     1.661: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    33/199    0.8696         0     1.651: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    34/199    0.8692         0     1.642: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    35/199    0.8627         0     1.635: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    36/199    0.8562         0     1.622: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    37/199    0.8501         0      1.62: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    38/199    0.8536         0     1.618: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    39/199    0.8495         0     1.617: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    40/199    0.8467         0     1.607: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:47<00:00,  2.08s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.61s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.66s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.46s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 40 | mAP@0.5: 0.1302752169640189 | mAP@0.50:0.95: 0.026505285414610842\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    41/199    0.8413         0     1.598: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    42/199      0.84         0     1.597: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    43/199    0.8309         0     1.586: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    44/199      0.83         0     1.579: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    45/199    0.8299         0     1.573: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    46/199    0.8229         0     1.572: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    47/199    0.8277         0     1.563: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    48/199    0.8206         0     1.563: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    49/199    0.8189         0     1.556: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    50/199     0.813         0      1.55: 100%|██████████| 178/178 [02:41<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    51/199    0.8103         0      1.54: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    52/199    0.8041         0     1.549: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    53/199    0.8058         0     1.532: 100%|██████████| 178/178 [02:44<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    54/199    0.8037         0     1.535: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    55/199    0.7937         0     1.505: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    56/199    0.7973         0     1.519: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    57/199     0.795         0     1.528: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    58/199    0.7892         0     1.511: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    59/199    0.7899         0     1.511: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    60/199    0.7869         0     1.504: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:45<00:00,  1.97s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.45s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 60 | mAP@0.5: 0.1945245149770696 | mAP@0.50:0.95: 0.051004877819761006\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    61/199    0.7841         0     1.498: 100%|██████████| 178/178 [02:38<00:00,  1.12it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    62/199    0.7769         0     1.488: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    63/199    0.7777         0     1.499: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    64/199    0.7776         0     1.487: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    65/199    0.7714         0     1.476: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    66/199    0.7662         0     1.478: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    67/199    0.7732         0     1.479: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    68/199     0.774         0     1.488: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    69/199    0.7674         0      1.47: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    70/199    0.7668         0     1.466: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    71/199    0.7628         0     1.466: 100%|██████████| 178/178 [02:41<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    72/199    0.7612         0     1.466: 100%|██████████| 178/178 [02:41<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    73/199    0.7557         0     1.447: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    74/199    0.7506         0     1.453: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    75/199    0.7501         0     1.445: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    76/199    0.7474         0     1.446: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    77/199    0.7414         0     1.445: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    78/199    0.7523         0     1.451: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    79/199    0.7446         0      1.44: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    80/199    0.7452         0     1.438: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:43<00:00,  1.87s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.90s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.45s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 80 | mAP@0.5: 0.15852038260079707 | mAP@0.50:0.95: 0.04460483923715882\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    81/199    0.7436         0     1.434: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    82/199    0.7352         0     1.424: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    83/199    0.7359         0     1.432: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    84/199    0.7233         0     1.414: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    85/199    0.7284         0     1.408: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    86/199     0.723         0     1.415: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    87/199    0.7229         0     1.416: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    88/199    0.7165         0     1.412: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    89/199    0.7274         0     1.422: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    90/199    0.7277         0     1.419: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    91/199    0.7143         0     1.398: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    92/199     0.714         0     1.399: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    93/199    0.7152         0     1.392: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    94/199    0.7055         0     1.398: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    95/199    0.7086         0     1.393: 100%|██████████| 178/178 [02:49<00:00,  1.05it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    96/199    0.7047         0      1.39: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    97/199    0.6967         0     1.379: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    98/199    0.6972         0     1.381: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "    99/199    0.6942         0     1.374: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   100/199    0.7028         0     1.388: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:41<00:00,  1.82s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.31s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.35s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 100 | mAP@0.5: 0.15471095313223934 | mAP@0.50:0.95: 0.042238779673317434\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   101/199     0.697         0     1.383: 100%|██████████| 178/178 [02:39<00:00,  1.12it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   102/199    0.6954         0     1.368: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   103/199    0.6926         0      1.38: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   104/199    0.6868         0     1.367: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   105/199    0.6878         0      1.37: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   106/199    0.6875         0     1.368: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   107/199     0.685         0     1.355: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   108/199    0.6758         0     1.361: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   109/199    0.6804         0     1.367: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   110/199    0.6706         0     1.345: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   111/199    0.6674         0      1.34: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   112/199    0.6758         0     1.353: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   113/199    0.6732         0     1.344: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   114/199    0.6662         0     1.347: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   115/199    0.6673         0     1.349: 100%|██████████| 178/178 [02:42<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   116/199    0.6531         0     1.329: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   117/199    0.6612         0     1.338: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   118/199     0.656         0     1.329: 100%|██████████| 178/178 [02:44<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   119/199     0.643         0     1.311: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   120/199    0.6607         0     1.332: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:41<00:00,  1.80s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=9.95s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.30s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.154\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 120 | mAP@0.5: 0.15385181610441748 | mAP@0.50:0.95: 0.04317880800225224\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   121/199    0.6466         0     1.319: 100%|██████████| 178/178 [02:39<00:00,  1.12it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   122/199    0.6441         0     1.314: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   123/199    0.6479         0     1.318: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   124/199    0.6428         0     1.317: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   125/199    0.6366         0     1.308: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   126/199    0.6309         0     1.298: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   127/199     0.629         0     1.288: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   128/199    0.6324         0     1.297: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   129/199    0.6265         0     1.297: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   130/199    0.6196         0     1.281: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   131/199     0.618         0      1.28: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   132/199    0.6195         0     1.287: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   133/199    0.6224         0     1.287: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   134/199    0.6155         0     1.282: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   135/199    0.6143         0     1.273: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   136/199     0.607         0     1.261: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   137/199    0.6005         0     1.255: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   138/199     0.596         0     1.246: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   139/199    0.5988         0     1.257: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   140/199    0.6051         0     1.256: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:40<00:00,  1.77s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=9.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.28s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 140 | mAP@0.5: 0.14161371133313744 | mAP@0.50:0.95: 0.03926623300043329\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   141/199     0.602         0     1.256: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   142/199    0.5845         0     1.241: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   143/199    0.5754         0     1.232: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   144/199    0.5903         0     1.249: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   145/199    0.5799         0     1.233: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   146/199    0.5837         0     1.247: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   147/199    0.5772         0     1.229: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   148/199    0.5715         0     1.219: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   149/199    0.5682         0     1.231: 100%|██████████| 178/178 [02:49<00:00,  1.05it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   150/199    0.5625         0     1.217: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:39<00:00,  1.73s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.70s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=9.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.138\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 150 | mAP@0.5: 0.13797011847940877 | mAP@0.50:0.95: 0.03887776126231101\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   151/199    0.5677         0     1.224: 100%|██████████| 178/178 [02:39<00:00,  1.12it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   152/199    0.5651         0     1.222: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   153/199    0.5539         0     1.201: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:39<00:00,  1.73s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.96s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.23s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 153 | mAP@0.5: 0.13722932651042463 | mAP@0.50:0.95: 0.03811481474347626\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   154/199    0.5561         0       1.2: 100%|██████████| 178/178 [02:42<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   155/199    0.5529         0     1.196: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   156/199    0.5537         0     1.202: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:39<00:00,  1.71s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.98s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=9.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.16s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 156 | mAP@0.5: 0.13660338505776942 | mAP@0.50:0.95: 0.03776595651819405\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   157/199    0.5503         0     1.198: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   158/199    0.5496         0     1.197: 100%|██████████| 178/178 [02:48<00:00,  1.05it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   159/199    0.5437         0     1.184: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:39<00:00,  1.72s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.58s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=9.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.12s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 159 | mAP@0.5: 0.13343023978648727 | mAP@0.50:0.95: 0.036973130907360305\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   160/199    0.5481         0     1.192: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   161/199    0.5368         0     1.183: 100%|██████████| 178/178 [02:47<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   162/199    0.5319         0     1.179: 100%|██████████| 178/178 [02:47<00:00,  1.06it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:38<00:00,  1.68s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.54s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.63s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 162 | mAP@0.5: 0.13123511176643507 | mAP@0.50:0.95: 0.03621886019534194\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   163/199    0.5236         0     1.165: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   164/199    0.5265         0     1.169: 100%|██████████| 178/178 [02:45<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   165/199    0.5199         0      1.16: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:38<00:00,  1.66s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.52s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.35s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.65s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 165 | mAP@0.5: 0.13046053506542973 | mAP@0.50:0.95: 0.03570663252448143\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   166/199    0.5203         0     1.165: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   167/199     0.516         0     1.152: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   168/199    0.5195         0     1.156: 100%|██████████| 178/178 [02:46<00:00,  1.07it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:38<00:00,  1.66s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.88s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.129\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 168 | mAP@0.5: 0.12855447437574863 | mAP@0.50:0.95: 0.035240645431093\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   169/199    0.5144         0     1.156: 100%|██████████| 178/178 [02:41<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   170/199    0.5115         0     1.154: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   171/199    0.5027         0     1.143: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:37<00:00,  1.64s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.50s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 171 | mAP@0.5: 0.12579874959590379 | mAP@0.50:0.95: 0.034801123436799745\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   172/199    0.5057         0     1.133: 100%|██████████| 178/178 [02:41<00:00,  1.10it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   173/199    0.4991         0     1.127: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   174/199    0.4909         0     1.114: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:37<00:00,  1.63s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.46s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=7.84s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.94s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 174 | mAP@0.5: 0.12277308902354786 | mAP@0.50:0.95: 0.033383000319984056\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   175/199    0.4897         0     1.119: 100%|██████████| 178/178 [02:39<00:00,  1.11it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   176/199    0.4902         0     1.124: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   177/199     0.485         0     1.114: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:37<00:00,  1.62s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.90s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=7.44s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.89s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 177 | mAP@0.5: 0.11954178581751283 | mAP@0.50:0.95: 0.03242174182106759\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   178/199    0.4778         0     1.106: 100%|██████████| 178/178 [02:38<00:00,  1.12it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   179/199    0.4827         0     1.102: 100%|██████████| 178/178 [02:44<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   180/199    0.4777         0     1.101: 100%|██████████| 178/178 [02:43<00:00,  1.09it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:36<00:00,  1.61s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.52s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=7.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.80s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 180 | mAP@0.5: 0.11486811953573926 | mAP@0.50:0.95: 0.03111713987313621\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   181/199    0.4725         0     1.098: 100%|██████████| 178/178 [02:41<00:00,  1.11it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   182/199    0.4747         0     1.102: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   183/199    0.4689         0     1.094: 100%|██████████| 178/178 [02:45<00:00,  1.08it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:36<00:00,  1.60s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.42s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=7.65s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.79s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.110\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 183 | mAP@0.5: 0.1103323821259078 | mAP@0.50:0.95: 0.02991349849394109\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   184/199     0.473         0     1.097: 100%|██████████| 178/178 [02:41<00:00,  1.10it/s]         \n",
            "Train: Final numbers of valid images: 11382/ labels: 11382. \n",
            "6.6s for dataset initialization.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Convert to COCO format\n",
            "100% 2862/2862 [00:00<00:00, 97099.32it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Research Project/Gold-YOLO/LDPolyp/annotations/instances_valid.json\n",
            "Val: Final numbers of valid images: 2862/ labels: 2862. \n",
            "2.0s for dataset initialization.\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   185/199    0.3603         0    0.9084: 100%|██████████| 178/178 [04:08<00:00,  1.40s/it]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   186/199    0.3356         0    0.8855: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:33<00:00,  1.46s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.37s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=7.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.72s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.106\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 186 | mAP@0.5: 0.10581196587629846 | mAP@0.50:0.95: 0.0290211624430137\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   187/199    0.3227         0     0.875: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   188/199    0.3192         0     0.867: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   189/199    0.3144         0    0.8585: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:32<00:00,  1.42s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.35s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.63s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 189 | mAP@0.5: 0.10266712093573085 | mAP@0.50:0.95: 0.02854325979937935\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   190/199    0.3104         0    0.8581: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   191/199    0.3024         0    0.8519: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   192/199    0.3023         0    0.8497: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:31<00:00,  1.39s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.29s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.61s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 192 | mAP@0.5: 0.0999136362771945 | mAP@0.50:0.95: 0.02783140283909625\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   193/199    0.3005         0    0.8437: 100%|██████████| 178/178 [02:19<00:00,  1.27it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   194/199    0.2957         0     0.839: 100%|██████████| 178/178 [02:19<00:00,  1.27it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   195/199    0.2943         0      0.84: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:30<00:00,  1.32s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.41s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.40s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 195 | mAP@0.5: 0.09683915922709364 | mAP@0.50:0.95: 0.026874732372999494\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   196/199    0.2922         0    0.8342: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   197/199    0.2984         0    0.8387: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   198/199    0.2959         0    0.8301: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:29<00:00,  1.28s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.84s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.24s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 198 | mAP@0.5: 0.09358349523544486 | mAP@0.50:0.95: 0.025903437941328072\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss\n",
            "   199/199    0.2932         0    0.8249: 100%|██████████| 178/178 [02:19<00:00,  1.28it/s]         \n",
            "\n",
            "Training completed in 9.740 hours.\n"
          ]
        }
      ],
      "source": [
        "!python tools/train.py --batch 64 --conf configs/gold_yolo-n.py --data \"/content/drive/MyDrive/Research Project/Gold-YOLO/data/dataset.yaml\" --epoch 200 --fuse_ab --device 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self distill training"
      ],
      "metadata": {
        "id": "5hVepNj7FyzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zgEiuNmYlRi",
        "outputId": "4fa3a2ec-e019-4098-f689-e9fc4a9c95de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-14 15:57:30.713760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-14 15:57:30.733897: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-14 15:57:30.740097: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-14 15:57:30.755189: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-14 15:57:31.830254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using 1 GPU for training... \n",
            "training args are: Namespace(data_path='data/dataset.yaml', conf_file='configs/gold_yolo-n.py', use_syncbn=True, img_size=640, batch_size=64, epochs=50, workers=8, device='0', eval_interval=20, eval_final_only=False, heavy_eval_range=50, check_images=False, check_labels=False, output_dir='./runs/train', name='exp', dist_url='env://', gpu_count=0, local_rank=-1, resume=False, write_trainbatch_tb=False, stop_aug_last_n_epoch=15, save_ckpt_on_last_n_epoch=-1, distill=True, distill_feat=False, quant=False, calib=False, teacher_model_path='runs/train/exp/weights/best_stop_aug_ckpt.pt', temperature=20, fuse_ab=False, bs_per_gpu=32, rank=-1, world_size=1, save_dir='runs/train/exp2')\n",
            "\n",
            "Train: Final numbers of valid images: 11382/ labels: 11382. \n",
            "2.0s for dataset initialization.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Convert to COCO format\n",
            "100% 2862/2862 [00:00<00:00, 152042.99it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Research Project/Gold-YOLO/LDPolyp/annotations/instances_valid.json\n",
            "Val: Final numbers of valid images: 2862/ labels: 2862. \n",
            "120.5s for dataset initialization.\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): Sequential(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): Sequential(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimCSPSPPF(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv4): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "        (cv5): SimConv(\n",
            "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv6): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv7): SimConv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepGDNeck(\n",
            "    (low_FAM): SimFusion_4in()\n",
            "    (low_IFM): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): Conv(\n",
            "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer_c5): SimConv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (LAF_p4): SimFusion_3in(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv_fuse): SimConv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Inject_p4): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer_p4): SimConv(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (LAF_p3): SimFusion_3in(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv_fuse): SimConv(\n",
            "        (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Inject_p3): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (high_FAM): PyramidPoolAgg()\n",
            "    (high_IFM): TopBasicLayer(\n",
            "      (transformer_blocks): ModuleList(\n",
            "        (0): top_Block(\n",
            "          (attn): Attention(\n",
            "            (to_q): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_k): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_v): Conv2d_BN(\n",
            "              (c): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (0): ReLU6(inplace=True)\n",
            "              (1): Conv2d_BN(\n",
            "                (c): Conv2d(64, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path): Identity()\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)\n",
            "            (act): ReLU6(inplace=True)\n",
            "            (fc2): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (drop): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): top_Block(\n",
            "          (attn): Attention(\n",
            "            (to_q): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_k): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_v): Conv2d_BN(\n",
            "              (c): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (0): ReLU6(inplace=True)\n",
            "              (1): Conv2d_BN(\n",
            "                (c): Conv2d(64, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)\n",
            "            (act): ReLU6(inplace=True)\n",
            "            (fc2): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (drop): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (conv_1x1_n): Conv2d(352, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (LAF_n4): AdvPoolFusion()\n",
            "    (Inject_n4): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (LAF_n5): AdvPoolFusion()\n",
            "    (Inject_n5): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n5): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds_lrtb): ModuleList(\n",
            "      (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Loading state_dict from runs/train/exp/weights/best_stop_aug_ckpt.pt for teacher\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): Sequential(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): Sequential(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimCSPSPPF(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv4): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "        (cv5): SimConv(\n",
            "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv6): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv7): SimConv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepGDNeck(\n",
            "    (low_FAM): SimFusion_4in()\n",
            "    (low_IFM): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): Conv(\n",
            "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer_c5): SimConv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (LAF_p4): SimFusion_3in(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv_fuse): SimConv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Inject_p4): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer_p4): SimConv(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (LAF_p3): SimFusion_3in(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv_fuse): SimConv(\n",
            "        (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Inject_p3): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (high_FAM): PyramidPoolAgg()\n",
            "    (high_IFM): TopBasicLayer(\n",
            "      (transformer_blocks): ModuleList(\n",
            "        (0): top_Block(\n",
            "          (attn): Attention(\n",
            "            (to_q): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_k): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_v): Conv2d_BN(\n",
            "              (c): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (0): ReLU6(inplace=True)\n",
            "              (1): Conv2d_BN(\n",
            "                (c): Conv2d(64, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path): Identity()\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)\n",
            "            (act): ReLU6(inplace=True)\n",
            "            (fc2): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (drop): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): top_Block(\n",
            "          (attn): Attention(\n",
            "            (to_q): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_k): Conv2d_BN(\n",
            "              (c): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (to_v): Conv2d_BN(\n",
            "              (c): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (0): ReLU6(inplace=True)\n",
            "              (1): Conv2d_BN(\n",
            "                (c): Conv2d(64, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)\n",
            "            (act): ReLU6(inplace=True)\n",
            "            (fc2): Conv2d_BN(\n",
            "              (c): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): SyncBatchNorm(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (drop): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (conv_1x1_n): Conv2d(352, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (LAF_n4): AdvPoolFusion()\n",
            "    (Inject_n4): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (LAF_n5): AdvPoolFusion()\n",
            "    (Inject_n5): InjectionMultiSum_Auto_pool(\n",
            "      (local_embedding): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_embedding): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (global_act): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (act): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n5): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_preds_af): ModuleList(\n",
            "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds_af): ModuleList(\n",
            "      (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (cls_preds_ab): ModuleList(\n",
            "      (0): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds_ab): ModuleList(\n",
            "      (0): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Training start...\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]                                                             /usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "      0/49     2.869         0    0.9596         0: 100%|██████████| 178/178 [03:10<00:00,  1.07s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:41<00:00,  1.81s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.93s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.32s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 0 | mAP@0.5: 0.03943044309139236 | mAP@0.50:0.95: 0.009428462934138912\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      1/49     2.105         0     1.001         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      2/49      1.68         0     1.078         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      3/49     1.535         0      1.12         0: 100%|██████████| 178/178 [03:00<00:00,  1.01s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [01:07<00:00,  2.94s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=5.56s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.66s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.46s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.136\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.349\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 3 | mAP@0.5: 0.02524055465598789 | mAP@0.50:0.95: 0.006614210005344812\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      4/49     1.429         0     1.163         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      5/49     1.341         0     1.204         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      6/49     1.251         0      1.22         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:56<00:00,  2.44s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=4.35s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.44s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.45s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 6 | mAP@0.5: 0.04160760075053611 | mAP@0.50:0.95: 0.009693535298147524\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      7/49     1.198         0     1.226         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      8/49     1.159         0     1.221         0: 100%|██████████| 178/178 [03:00<00:00,  1.01s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "      9/49     1.131         0     1.211         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [01:04<00:00,  2.80s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=5.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.72s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.39s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 9 | mAP@0.5: 0.04154424736260173 | mAP@0.50:0.95: 0.010142900906232868\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     10/49     1.103         0     1.201         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     11/49     1.085         0     1.189         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     12/49     1.066         0     1.173         0: 100%|██████████| 178/178 [03:00<00:00,  1.01s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:48<00:00,  2.10s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=3.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.53s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 12 | mAP@0.5: 0.026351129933931395 | mAP@0.50:0.95: 0.005751182982480348\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     13/49     1.051         0     1.149         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     14/49     1.037         0     1.124         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     15/49     1.018         0     1.097         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:48<00:00,  2.12s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.92s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.38s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.202\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 15 | mAP@0.5: 0.06369458997192678 | mAP@0.50:0.95: 0.017144532954189176\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     16/49     1.001         0     1.076         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     17/49    0.9943         0     1.051         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     18/49    0.9728         0     1.022         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:53<00:00,  2.34s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=4.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 18 | mAP@0.5: 0.05072292043012447 | mAP@0.50:0.95: 0.010794622164783052\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     19/49    0.9616         0     1.008         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     20/49    0.9408         0    0.9841         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     21/49    0.9306         0    0.9699         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:49<00:00,  2.17s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=3.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.30s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.53s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 21 | mAP@0.5: 0.08624692191030045 | mAP@0.50:0.95: 0.021818507787754387\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     22/49    0.9168         0    0.9589         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     23/49    0.9023         0    0.9391         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     24/49    0.8966         0    0.9311         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:48<00:00,  2.10s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.94s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.48s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 24 | mAP@0.5: 0.05957679370618456 | mAP@0.50:0.95: 0.011733616002001207\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     25/49     0.888         0    0.9208         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     26/49     0.873         0    0.9044         0: 100%|██████████| 178/178 [03:00<00:00,  1.01s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     27/49    0.8575         0    0.8894         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:44<00:00,  1.95s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.75s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.39s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 27 | mAP@0.5: 0.1600600231819236 | mAP@0.50:0.95: 0.0292312559500968\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     28/49    0.8506         0    0.8887         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     29/49    0.8314         0    0.8736         0: 100%|██████████| 178/178 [03:00<00:00,  1.01s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     30/49    0.8236         0     0.863         0: 100%|██████████| 178/178 [03:00<00:00,  1.01s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:43<00:00,  1.90s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.21s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.83s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.51s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 30 | mAP@0.5: 0.1431149294331153 | mAP@0.50:0.95: 0.030723599158693056\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     31/49    0.8122         0    0.8508         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     32/49    0.7982         0    0.8431         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     33/49     0.786         0    0.8277         0: 100%|██████████| 178/178 [03:00<00:00,  1.02s/it\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:44<00:00,  1.94s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.81s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.39s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 33 | mAP@0.5: 0.036932116206404964 | mAP@0.50:0.95: 0.007876507464800122\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     34/49    0.7709         0    0.8198         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "Train: Final numbers of valid images: 11382/ labels: 11382. \n",
            "7.1s for dataset initialization.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Convert to COCO format\n",
            "100% 2862/2862 [00:00<00:00, 93873.69it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Research Project/Gold-YOLO/LDPolyp/annotations/instances_valid.json\n",
            "Val: Final numbers of valid images: 2862/ labels: 2862. \n",
            "116.6s for dataset initialization.\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     35/49    0.6679         0    0.7007         0: 100%|██████████| 178/178 [03:01<00:00,  1.02s/it\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     36/49    0.6273         0    0.6626         0: 100%|██████████| 178/178 [02:55<00:00,  1.02it/s\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:31<00:00,  1.35s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.26s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.25s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.203\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 36 | mAP@0.5: 0.14180337170572357 | mAP@0.50:0.95: 0.03522238910950498\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     37/49    0.6013         0      0.64         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     38/49    0.5722         0    0.6194         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     39/49    0.5554         0    0.6021         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:25<00:00,  1.13s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.48s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.58s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.75s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 39 | mAP@0.5: 0.13496810537200182 | mAP@0.50:0.95: 0.03681678320258543\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     40/49    0.5367         0     0.591         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     41/49    0.5101         0    0.5733         0: 100%|██████████| 178/178 [02:55<00:00,  1.02it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     42/49    0.4947         0     0.562         0: 100%|██████████| 178/178 [02:55<00:00,  1.02it/s\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:24<00:00,  1.07s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.62s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 42 | mAP@0.5: 0.13070308702008177 | mAP@0.50:0.95: 0.03619274507106431\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     43/49    0.4794         0      0.55         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     44/49    0.4606         0    0.5442         0: 100%|██████████| 178/178 [02:55<00:00,  1.02it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     45/49     0.453         0    0.5314         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:24<00:00,  1.06s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.32s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.41s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.60s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.173\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 45 | mAP@0.5: 0.11461466919105621 | mAP@0.50:0.95: 0.031066863229013714\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     46/49    0.4355         0    0.5267         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     47/49    0.4221         0    0.5169         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     48/49    0.4143         0    0.5107         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 23/23 [00:24<00:00,  1.07s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.62s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
            "Results saved to runs/train/exp2\n",
            "Epoch: 48 | mAP@0.5: 0.11341983389675232 | mAP@0.50:0.95: 0.02919193517671398\n",
            "\n",
            "     Epoch  iou_loss  dfl_loss  cls_loss  cwd_loss\n",
            "     49/49    0.4033         0    0.5032         0: 100%|██████████| 178/178 [02:55<00:00,  1.01it/s\n",
            "\n",
            "Training completed in 2.854 hours.\n"
          ]
        }
      ],
      "source": [
        "!python tools/train.py \\\n",
        "\t\t\t\t\t\t\t\t\t--batch 64 \\\n",
        "\t\t\t\t\t\t\t\t\t--conf configs/gold_yolo-n.py \\\n",
        "\t\t\t\t\t\t\t\t\t--data data/dataset.yaml \\\n",
        "\t\t\t\t\t\t\t\t\t--epoch 50 \\\n",
        "\t\t\t\t\t\t\t\t\t--device 0 \\\n",
        "\t\t\t\t\t\t\t\t\t--use_syncbn \\\n",
        "\t\t\t\t\t\t\t\t\t--distill \\\n",
        "\t\t\t\t\t\t\t\t\t--teacher_model_path runs/train/exp/weights/best_stop_aug_ckpt.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Validation data"
      ],
      "metadata": {
        "id": "i4hNPepiF3er"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06LzSNsDvVmn",
        "outputId": "f2d5df8b-4eb4-4bc3-b909-5cff90350898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data='/content/drive/MyDrive/Research Project/Gold-YOLO/data/dataset.yaml', weights='runs/train/exp2/weights/best_ckpt.pt', batch_size=64, img_size=640, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='exp', test_load_size=638, letterbox_return_int=True, scale_exact=True, force_no_pad=True, not_infer_on_rect=True, reproduce_640_eval=True, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=False, plot_curve=True, plot_confusion_matrix=False, verbose=False, config_file='')\n",
            "Loading checkpoint from runs/train/exp2/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Switch model to deploy modality.\n",
            "Model Summary: Params: 5.60M, Gflops: 12.05\n",
            "Val: Checking formats of labels with 8 process(es): \n",
            "2862 label(s) found, 0 label(s) missing, 300 label(s) empty, 0 invalid label files: 100% 2862/2862 [00:04<00:00, 625.81it/s]\n",
            "Convert to COCO format\n",
            "100% 2862/2862 [00:00<00:00, 175017.47it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Research Project/Gold-YOLO/LDPolyp/annotations/instances_valid.json\n",
            "Val: Final numbers of valid images: 2862/ labels: 2862. \n",
            "5.4s for dataset initialization.\n",
            "Inferencing model in val datasets.: 100%|███████████████████████████| 45/45 [00:46<00:00,  1.04s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "Average pre-process time: 0.22 ms\n",
            "Average inference time: 3.62 ms\n",
            "Average NMS time: 1.40 ms\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/val/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.56s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.68s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.87s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            "Results saved to runs/val/exp\n"
          ]
        }
      ],
      "source": [
        "!python tools/eval.py --data \"/content/drive/MyDrive/Research Project/Gold-YOLO/data/dataset.yaml\" --batch 64 --weights runs/train/exp2/weights/best_ckpt.pt --task val --reproduce_640_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on TEST data"
      ],
      "metadata": {
        "id": "3Q9X10dVF-LG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYDAg5c-vsP3",
        "outputId": "7797516e-1d03-4e22-a203-f93ed2a9f64a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights='runs/train/exp2/weights/best_ckpt.pt', source='/content/drive/My Drive/Research Project/Gold-YOLO/LDPolyp/images/test', yaml='/content/drive/My Drive/Research Project/Gold-YOLO/data/dataset.yaml', img_size=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device='0', save_txt=True, not_save_img=False, save_dir='/content/drive/My Drive/Research Project/Gold-YOLO/runs', view_img=False, classes=None, agnostic_nms=False, project='runs/inference', name='exp', hide_labels=False, hide_conf=False, half=False)\n",
            "Save directory already existed\n",
            "Loading checkpoint from runs/train/exp2/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "Switch model to deploy modality.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100% 1411/1411 [01:21<00:00, 17.36it/s]\n",
            "Results saved to /content/drive/My Drive/Research Project/Gold-YOLO/runs\n"
          ]
        }
      ],
      "source": [
        "!python tools/infer.py --source \"/content/drive/My Drive/Research Project/Gold-YOLO/LDPolyp/images/test\" --yaml \"/content/drive/My Drive/Research Project/Gold-YOLO/data/dataset.yaml\" --weights runs/train/exp2/weights/best_ckpt.pt --save-dir \"/content/drive/My Drive/Research Project/Gold-YOLO/runs\" --save-txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on test data"
      ],
      "metadata": {
        "id": "SQ9rPx8AGCif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/eval.py  --data \"/content/drive/My Drive/Research Project/Gold-YOLO/data/dataset.yaml\" --task test --weights runs/train/exp2/weights/best_ckpt.pt --save_dir \"/content/drive/My Drive/Research Project/Gold-YOLO/runs\" --plot_confusion_matrix --plot_curve True --do_pr_metric True --name \"test\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbQOTnZkEe2M",
        "outputId": "65947eb5-8642-49fa-bfe9-78c5e5e43490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data='/content/drive/My Drive/Research Project/Gold-YOLO/data/dataset.yaml', weights='runs/train/exp2/weights/best_ckpt.pt', batch_size=32, img_size=640, conf_thres=0.03, iou_thres=0.65, task='test', device='0', half=False, save_dir='/content/drive/My Drive/Research Project/Gold-YOLO/runs', name='test', test_load_size=640, letterbox_return_int=False, scale_exact=False, force_no_pad=False, not_infer_on_rect=False, reproduce_640_eval=False, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=True, plot_curve=True, plot_confusion_matrix=True, verbose=False, config_file='')\n",
            "Loading checkpoint from runs/train/exp2/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Switch model to deploy modality.\n",
            "Model Summary: Params: 5.60M, Gflops: 12.05\n",
            "Test: Checking formats of images with 8 process(es): \n",
            "0 image(s) corrupted: 100% 1411/1411 [00:39<00:00, 35.96it/s] \n",
            "Test: Checking formats of labels with 8 process(es): \n",
            "1411 label(s) found, 0 label(s) missing, 219 label(s) empty, 0 invalid label files: 100% 1411/1411 [01:48<00:00, 12.95it/s]\n",
            "Test: Final numbers of valid images: 1411/ labels: 1411. \n",
            "149.1s for dataset initialization.\n",
            "Inferencing model in test datasets.: 100%|██████████████████████████| 45/45 [00:17<00:00,  2.62it/s]\n",
            "IOU 50 best mF1 thershold near 0.302.\n",
            "Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95\n",
            "all                     1411        1192       0.644       0.353       0.456        0.41       0.231\n",
            "\n",
            "Evaluating speed.\n",
            "Average pre-process time: 0.17 ms\n",
            "Average inference time: 3.72 ms\n",
            "Average NMS time: 1.74 ms\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving /content/drive/My Drive/Research Project/Gold-YOLO/runs/test/predictions.json...\n",
            "loading annotations into memory...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/tools/eval.py\", line 164, in <module>\n",
            "    main(args)\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/tools/eval.py\", line 159, in main\n",
            "    run(**vars(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/tools/eval.py\", line 154, in run\n",
            "    eval_result = val.eval_model(pred_result, model, dataloader, task)\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/yolov6/core/evaler.py\", line 268, in eval_model\n",
            "    anno = COCO(anno_json)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pycocotools/coco.py\", line 81, in __init__\n",
            "    with open(annotation_file, 'r') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Research Project/Gold-YOLO/LDPolyp/annotations/instances_test.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/eval.py  --data \"/content/drive/My Drive/Research Project/Gold-YOLO/data/dataset.yaml\" --task test --weights runs/train/exp/weights/best_ckpt.pt --save_dir \"/content/drive/My Drive/Research Project/Gold-YOLO/runs\" --plot_confusion_matrix --plot_curve True --do_pr_metric True --name \"test\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxzTH8mEzQpY",
        "outputId": "09f3eb3d-5f3a-491c-e3d5-d428b400cf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data='/content/drive/My Drive/Research Project/Gold-YOLO/data/dataset.yaml', weights='runs/train/exp/weights/best_ckpt.pt', batch_size=32, img_size=640, conf_thres=0.03, iou_thres=0.65, task='test', device='0', half=False, save_dir='/content/drive/My Drive/Research Project/Gold-YOLO/runs', name='test', test_load_size=640, letterbox_return_int=False, scale_exact=False, force_no_pad=False, not_infer_on_rect=False, reproduce_640_eval=False, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=True, plot_curve=True, plot_confusion_matrix=True, verbose=False, config_file='')\n",
            "Loading checkpoint from runs/train/exp/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Switch model to deploy modality.\n",
            "Model Summary: Params: 5.60M, Gflops: 12.05\n",
            "Test: Checking formats of labels with 8 process(es): \n",
            "1411 label(s) found, 0 label(s) missing, 219 label(s) empty, 0 invalid label files: 100% 1411/1411 [01:19<00:00, 17.82it/s]\n",
            "Test: Final numbers of valid images: 1411/ labels: 1411. \n",
            "80.5s for dataset initialization.\n",
            "Inferencing model in test datasets.: 100%|██████████████████████████| 45/45 [00:51<00:00,  1.14s/it]\n",
            "IOU 50 best mF1 thershold near 0.312.\n",
            "Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95\n",
            "all                     1411        1192       0.796       0.473       0.593       0.555        0.38\n",
            "\n",
            "Evaluating speed.\n",
            "Average pre-process time: 0.17 ms\n",
            "Average inference time: 3.72 ms\n",
            "Average NMS time: 1.71 ms\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving /content/drive/My Drive/Research Project/Gold-YOLO/runs/test1/predictions.json...\n",
            "loading annotations into memory...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/tools/eval.py\", line 164, in <module>\n",
            "    main(args)\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/tools/eval.py\", line 159, in main\n",
            "    run(**vars(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/tools/eval.py\", line 154, in run\n",
            "    eval_result = val.eval_model(pred_result, model, dataloader, task)\n",
            "  File \"/content/drive/MyDrive/Research Project/Gold-YOLO/yolov6/core/evaler.py\", line 268, in eval_model\n",
            "    anno = COCO(anno_json)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pycocotools/coco.py\", line 81, in __init__\n",
            "    with open(annotation_file, 'r') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Research Project/Gold-YOLO/LDPolyp/annotations/instances_test.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3WV5OJzHKT1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}